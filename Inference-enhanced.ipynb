{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch numpy matplotlib opencv-python boto3 cryptography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from src.s3_utils import download_model_weights\n",
    "from src.decrypt_utils import decrypt_weights\n",
    "\n",
    "def load_model_weights(weight_path, s3_bucket=None, s3_key=None):\n",
    "    if s3_bucket and s3_key:\n",
    "        try:\n",
    "            encrypted_weights_path = download_model_weights(s3_bucket, s3_key)\n",
    "            weight_path = decrypt_weights(encrypted_weights_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load weights from S3: {e}\")\n",
    "            print(\"Falling back to local weights...\")\n",
    "    return weight_path\n",
    "\n",
    "samples_path = '/Users/raheelzubairi/Documents/projects/pixelence/v2/_samples_/'\n",
    "weight_path = load_model_weights(\n",
    "    '/Users/raheelzubairi/Documents/projects/pixelence/v2/_weights_/_global1.pth',\n",
    "    s3_bucket='your-s3-bucket-name',\n",
    "    s3_key='path/to/encrypted_weights.pth'\n",
    ")  # Update with your S3 bucket and key\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "size = (182, 182, 22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastEnhancementBlock3D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ContrastEnhancementBlock3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(channels)\n",
    "        self.conv2 = nn.Conv3d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(channels)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool3d(1)\n",
    "        self.fc1 = nn.Conv3d(channels, channels // 4, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv3d(channels // 4, channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        local = nn.Sequential(\n",
    "            self.conv1, self.bn1, self.relu, self.conv2, self.bn2\n",
    "        )(x)\n",
    "\n",
    "        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n",
    "        attention = self.sigmoid(avg_out + max_out)\n",
    "\n",
    "        out = x + local * attention\n",
    "        return self.relu(out)\n",
    "\n",
    "class CBAM3D(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=8, spatial_kernel=7):\n",
    "        super(CBAM3D, self).__init__()\n",
    "        self.channel_attention = ChannelAttention3D(in_channels, reduction)\n",
    "        self.spatial_attention = SpatialAttention3D(spatial_kernel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        x = self.spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "class UNet3D_Deep_Supervision_attention_cbam(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, base_filters=32):\n",
    "        super(UNet3D_Deep_Supervision_attention_cbam, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.base_filters = base_filters\n",
    "\n",
    "        def conv_block(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv3d(in_c, out_c, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm3d(out_c),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv3d(out_c, out_c, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm3d(out_c),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        self.encoder1 = conv_block(self.in_channels, self.base_filters)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = conv_block(self.base_filters, self.base_filters * 2)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        self.enc_attent2 = CBAM3D(self.base_filters * 2)\n",
    "        self.encoder3 = conv_block(self.base_filters * 2, self.base_filters * 4)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        self.enc_attent3 = CBAM3D(self.base_filters * 4)\n",
    "        self.bottleneck = conv_block(self.base_filters * 4, self.base_filters * 8)\n",
    "        self.bottleneck_attent = CBAM3D(self.base_filters * 8)\n",
    "        self.up3 = nn.ConvTranspose3d(self.base_filters * 8, self.base_filters * 4, kernel_size=2, stride=2)\n",
    "        self.attent3 = CBAM3D(self.base_filters * 4)\n",
    "        self.decoder3 = conv_block(self.base_filters * 8, self.base_filters * 4)\n",
    "        self.dec3_drop = nn.Dropout3d(0.25)\n",
    "        self.ds3_out = nn.Conv3d(self.base_filters * 4, self.out_channels, kernel_size=1)\n",
    "        self.up2 = nn.ConvTranspose3d(self.base_filters * 4, self.base_filters * 2, kernel_size=2, stride=2)\n",
    "        self.attent2 = CBAM3D(self.base_filters * 2)\n",
    "        self.decoder2 = conv_block(self.base_filters * 4, self.base_filters * 2)\n",
    "        self.dec2_drop = nn.Dropout3d(0.25)\n",
    "        self.ds2_out = nn.Conv3d(self.base_filters * 2, self.out_channels, kernel_size=1)\n",
    "        self.up1 = nn.ConvTranspose3d(self.base_filters * 2, self.base_filters, kernel_size=2, stride=2)\n",
    "        self.attent1 = CBAM3D(self.base_filters)\n",
    "        self.decoder1 = conv_block(self.base_filters * 2, self.base_filters)\n",
    "        self.dec1_drop = nn.Dropout3d(0.25)\n",
    "        self.output_conv = nn.Conv3d(self.base_filters, self.out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass implementation\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [samples_path+i for i in os.listdir(samples_path)]\n",
    "for f_ in range(len(files)):\n",
    "    print(f'Case {f_}')\n",
    "    show_example(files[f_])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".ipynb",
   "mimetype": "application/x-ipynb+json",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}